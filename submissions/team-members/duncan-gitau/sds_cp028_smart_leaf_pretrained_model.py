# -*- coding: utf-8 -*-
"""SDS-CP028-smart-leaf-pretrained-model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sAZM4kEySgbcSEl6Z5DIF9cDr9gzvQMb

**Loading and Preprocessing Image Datasets with PyTorch**

Link to Dataset: https://www.kaggle.com/datasets/nafishamoin/new-bangladeshi-crop-disease

1. Install Libraries
"""

# !pip install torch
# !pip install torchvision
# !pip install numpy
# !pip install matplotlib

"""2. Importing libraries"""

# !pip install torchvision

import torch
import torchvision
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np
import time
import seaborn
import matplotlib.pyplot as plt

# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Hyperparameters
NUM_CLASSES = 14
batch_size = 32
EPOCHS = 10
LEARNING_RATE = 1e-4
IMAGE_SIZE = 224

"""3. **Loading the Dataset**

   We will use the torchvision.datasets.ImageFolder to load the dataset.
   
   **Generate a Kaggle API Key**
   Go to your Kaggle account settings: https://www.kaggle.com/account/account

   Scroll down to the "API" section.

   Click on "Create New API Token".

   This will download a file named kaggle.json containing your API key.
   Upload the Kaggle API Key to Google Colab                                                
   In your Google Colab notebook, create a new cell and run the following code
   to upload the kaggle.json file:                                                                        Click on "Choose Files" and select the kaggle.json file from your local machine.        

"""

from google.colab import drive
drive.mount("/content/drive")

from google.colab import files
files.upload()

"""       Move the API Key to the Correct Directory
       Run the following commands in a new cell to create the .kaggle directory and move the kaggle.json file to it:
       
"""

!mkdir -p ~/.kaggle
!mv kaggle2.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle2.json

"""      Download the Dataset
      
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("nafishamoin/new-bangladeshi-crop-disease")

print("Path to dataset files:", path)

!mkdir -p ./SDS-CP028
#!mv /root/.cache/kagglehub/datasets/nafishamoin/new-bangladeshi-crop-disease/versions/2 ./SDS-CP028/

!cp -r /kaggle/input/new-bangladeshi-crop-disease ./SDS-CP028/

import os
import shutil
import random

# Set random seed for reproducibility
random.seed(42)

# Paths
original_dataset_dir = './SDS-CP028/new-bangladeshi-crop-disease/BangladeshiCrops/BangladeshiCrops/Crop___Disease'  # Root path where Corn, Potato, etc. folders are
base_dir = 'SmartLeaf_dataset'                            # Where you want to create train/val/test folders
train_dir = os.path.join(base_dir, 'train')
val_dir = os.path.join(base_dir, 'val')
test_dir = os.path.join(base_dir, 'test')

# Split ratios
train_ratio = 0.8
val_ratio = 0.1
# test_ratio = 0.1 (implicitly the remaining)

# Create train, val, and test directories
for split_dir in [train_dir, val_dir, test_dir]:
    os.makedirs(split_dir, exist_ok=True)

# Traverse two levels: crop -> class
for crop_folder in os.listdir(original_dataset_dir):
    crop_path = os.path.join(original_dataset_dir, crop_folder)

    if os.path.isdir(crop_path):
        # Now go inside each disease class
        for class_folder in os.listdir(crop_path):
            class_path = os.path.join(crop_path, class_folder)

            if os.path.isdir(class_path):
                images = os.listdir(class_path)
                random.shuffle(images)

                total_images = len(images)
                train_split = int(total_images * train_ratio)
                val_split = int(total_images * (train_ratio + val_ratio))

                train_images = images[:train_split]
                val_images = images[train_split:val_split]
                test_images = images[val_split:]

                # Create corresponding class folders under train/val/test
                train_class_dir = os.path.join(train_dir, class_folder)
                val_class_dir = os.path.join(val_dir, class_folder)
                test_class_dir = os.path.join(test_dir, class_folder)

                os.makedirs(train_class_dir, exist_ok=True)
                os.makedirs(val_class_dir, exist_ok=True)
                os.makedirs(test_class_dir, exist_ok=True)

                # Copy images
                for img in train_images:
                    shutil.copy2(os.path.join(class_path, img), os.path.join(train_class_dir, img))

                for img in val_images:
                    shutil.copy2(os.path.join(class_path, img), os.path.join(val_class_dir, img))

                for img in test_images:
                    shutil.copy2(os.path.join(class_path, img), os.path.join(test_class_dir, img))

print("Dataset split into train/val/test successfully!")

"""4. Preprocessing the Dataset

   Preprocessing is an essential step in preparing the data for training. Common preprocessing steps include resizing, normalization, and data augmentation.

  Define the transformations:
"""

# Data transforms
transform_train = transforms.Compose([
    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

transform_val = transforms.Compose([
    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

"""5.  Creating Data Loaders
  Data loaders in PyTorch help in efficiently loading data during training.
  We will create a data loader for our training dataset.
"""

# Create datasets
train_dataset = torchvision.datasets.ImageFolder(root='SmartLeaf_dataset/train', transform=transform_train)
test_dataset = torchvision.datasets.ImageFolder(root='SmartLeaf_dataset/test', transform=transform_val)
eval_dataset = torchvision.datasets.ImageFolder(root='SmartLeaf_dataset/val', transform=transform_val)

# Create loaders
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
eval_loader = torch.utils.data.DataLoader(eval_dataset, batch_size=batch_size, shuffle=False)

# %%
CLASSES = ['Corn___Common_Rust', 'Corn___Gray_Leaf_Spot', 'Corn___Healthy','Corn___Northern_Leaf_Blight',
           'Potato___Early_Blight','Potato___Healthy','Potato___Late_Blight','Rice___Brown_Spot','Rice___Healthy',
           'Rice___Leaf_Blast','Rice___Neck_Blast','Wheat___Brown_Rust','Wheat___Healthy','Wheat___Yellow_Rust',
        ]
NUM_CLASSES = len(CLASSES)

NUM_CLASSES

"""5.1 Show sample images"""

def imshow(image_torch):
    # flip image channels to RGB
    image_torch = image_torch.numpy().transpose((1, 2, 0))
    plt.figure()
    plt.imshow(image_torch)

X_train, y_train = next(iter(train_loader))

# Make a grid from batch
image_grid = torchvision.utils.make_grid(X_train[:16, :, :, :], scale_each= True, nrow=4)

imshow(image_grid)

"""6. Download and instantiate pre-trained network"""

model = models.resnet50(pretrained=True)

"""  6.1 Freeze the layers"""

#Freeze all layers
for params in model.parameters():
    params.requires_grad = False

model.fc = nn.Sequential(
    nn.Linear(model.fc.in_features, 256),
    nn.ReLU(),
    nn.Dropout(0.3),
    nn.Linear(256, NUM_CLASSES)
)

model = model.to(device)

"""7. Train the Model"""

# %%
criterion = nn.CrossEntropyLoss()
train_losses=[]
optimizer = torch.optim.Adam(model.parameters(),lr=LEARNING_RATE)

# Training and evaluation functions
def train(model, loader, optimizer, criterion):
    model.train()
    total_loss, correct = 0, 0
    for imgs, labels in loader:
        imgs, labels = imgs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
        correct += (outputs.argmax(1) == labels).sum().item()
    return total_loss / len(loader), correct / len(loader.dataset)

def evaluate(model, loader, criterion):
    model.eval()
    total_loss, correct = 0, 0
    with torch.no_grad():
        for imgs, labels in loader:
            imgs, labels = imgs.to(device), labels.to(device)
            outputs = model(imgs)
            loss = criterion(outputs, labels)
            total_loss += loss.item()
            correct += (outputs.argmax(1) == labels).sum().item()
    return total_loss / len(loader), correct / len(loader.dataset)

# Train loop
for epoch in range(EPOCHS):
    train_loss, train_acc = train(model, train_loader, optimizer, criterion)
    eval_loss, eval_acc = evaluate(model, eval_loader, criterion)
    print(f"Epoch {epoch+1}/{EPOCHS} | Train Acc: {train_acc:.4f}, Eval Acc: {eval_acc:.4f}")

# Evaluate on test set
def evaluate_test(model, loader):
    model.eval()
    all_preds = []
    all_labels = []
    with torch.no_grad():
        for imgs, labels in loader:
            imgs = imgs.to(device)
            outputs = model(imgs)
            preds = outputs.argmax(1).cpu().numpy()
            all_preds.extend(preds)
            all_labels.extend(labels.numpy())
    return all_labels, all_preds

y_true, y_pred = evaluate_test(model, test_loader)

# Report
print("\nClassification Report:")
print(classification_report(y_true, y_pred, target_names=test_dataset.classes))

print("Confusion Matrix:")
print(confusion_matrix(y_true, y_pred))

# Save the model
torch.save(model.state_dict(), "resnet50_crop_disease.pth")

"""8. Evaluate the Model

9. Test the Model

10. Save Model
"""

# Define the model architecture
model = models.resnet50(pretrained=False)
model.eval()
# Modify the final layer to match the structure used during training
num_classes = 14
model.fc = nn.Sequential(
    nn.Linear(model.fc.in_features, 256),
    nn.ReLU(),
    nn.Dropout(0.3),
    nn.Linear(256, num_classes)
)

# Load the saved state_dict
model.load_state_dict(torch.load("resnet50_crop_disease.pth"))

# Set the model to evaluation mode (for inference)
model.eval()

"""11. Loading the Model Weights

12. Performing Inference:
"""

# Sample inference for a new image

# Assume you have a test image that you want to classify
from PIL import Image

# Load your image
image_path = '/content/SDS-CP028/new-bangladeshi-crop-disease/BangladeshiCrops/BangladeshiCrops/Crop___Disease/Corn/Corn___Common_Rust/image (10).JPG'
image = Image.open(image_path)

# Apply the same transformations that you used for training
transform_val = transforms.Compose([
    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])


image_tensor = transform_val(image).unsqueeze(0)  # Add batch dimension: (1, 1, 32, 32)

# Perform inference
with torch.no_grad():
    output = model(image_tensor)  # Forward pass
    _, predicted = torch.max(output, 1)  # Get the class with the highest score

# Print predicted class
predicted_class = CLASSES[predicted.item()]
print(f"Predicted class: {predicted_class}")

