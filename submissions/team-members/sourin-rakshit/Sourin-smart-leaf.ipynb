{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2b9975",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Importing the Libraries\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import kagglehub\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d52ab62",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beacc4c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Download & point to the right directory\n",
    "path = kagglehub.dataset_download(\"nafishamoin/new-bangladeshi-crop-disease\")\n",
    "dataset_path = \"/Users/sourinrakshit/.cache/kagglehub/datasets/nafishamoin/new-bangladeshi-crop-disease/versions/2/BangladeshiCrops/BangladeshiCrops/Crop___Disease\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98f3cfc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Dataset class\n",
    "class CropDiseaseDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes, self.class_to_idx = self._find_classes()\n",
    "        self.samples = self._make_dataset()\n",
    "\n",
    "    def _find_classes(self):\n",
    "        classes = []\n",
    "        for main_class in os.listdir(self.root_dir):\n",
    "            main_path = os.path.join(self.root_dir, main_class)\n",
    "            if not os.path.isdir(main_path):\n",
    "                continue\n",
    "            for subclass in os.listdir(main_path):\n",
    "                subclass_path = os.path.join(main_path, subclass)\n",
    "                if not os.path.isdir(subclass_path):\n",
    "                    continue\n",
    "                classes.append(f\"{main_class}_{subclass.split('_')[-3]}_{subclass.split('_')[-2]}_{subclass.split('_')[-1]}\")\n",
    "        classes = sorted(set(classes))\n",
    "        return classes, {c: i for i, c in enumerate(classes)}\n",
    "\n",
    "    def _make_dataset(self):\n",
    "        samples = []\n",
    "        for main_class in os.listdir(self.root_dir):\n",
    "            main_path = os.path.join(self.root_dir, main_class)\n",
    "            if not os.path.isdir(main_path):\n",
    "                continue\n",
    "            for subclass in os.listdir(main_path):\n",
    "                subclass_path = os.path.join(main_path, subclass)\n",
    "                if not os.path.isdir(subclass_path):\n",
    "                    continue\n",
    "                label = self.class_to_idx[f\"{main_class}_{subclass.split('_')[-3]}_{subclass.split('_')[-2]}_{subclass.split('_')[-1]}\"]\n",
    "                for fn in os.listdir(subclass_path):\n",
    "                    file_path = os.path.join(subclass_path, fn)\n",
    "                    if not os.path.isfile(file_path):\n",
    "                        continue\n",
    "                    samples.append((file_path, label))\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fn, label = self.samples[idx]\n",
    "        img = Image.open(fn).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14d6e6c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 3. Transforms\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.2),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),\n",
    "    transforms.RandomPerspective(distortion_scale=0.2, p=0.3),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.3, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_test_tf = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6085429",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 4. Load dataset & compute class weights\n",
    "full_ds = CropDiseaseDataset(dataset_path, transform=None)\n",
    "labels = [lbl for _, lbl in full_ds.samples]\n",
    "num_classes = len(full_ds.classes)\n",
    "cw = compute_class_weight(\"balanced\", classes=np.arange(num_classes), y=labels)\n",
    "class_weights = torch.tensor(cw, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf57fa5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 5. Stratified split\n",
    "sss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_val_idx, test_idx = next(sss1.split(np.zeros(len(labels)), labels))\n",
    "\n",
    "train_val_labels = [labels[i] for i in train_val_idx]\n",
    "sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, val_idx = next(sss2.split(np.zeros(len(train_val_labels)), train_val_labels))\n",
    "\n",
    "train_idx = [train_val_idx[i] for i in train_idx]\n",
    "val_idx = [train_val_idx[i] for i in val_idx]\n",
    "\n",
    "train_ds = Subset(full_ds, train_idx)\n",
    "train_ds.dataset.transform = train_tf\n",
    "\n",
    "val_ds = Subset(full_ds, val_idx)\n",
    "val_ds.dataset.transform = val_test_tf\n",
    "\n",
    "test_ds = Subset(full_ds, test_idx)\n",
    "test_ds.dataset.transform = val_test_tf\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=0)\n",
    "test_loader  = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9122b7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 6. Model\n",
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3,32,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64,128,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128*28*28,512), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(512,num_classes)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "model = BasicCNN(num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e509f919",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 7. Loss, optimizer\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0948eda4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "best_acc, patience, counter = 0.0, 5, 0\n",
    "\n",
    "for epoch in range(1, 21):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x,y in tqdm(train_loader, desc=f\"Epoch {epoch}/10 [Train]\"):\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(x), y)\n",
    "        loss.backward(); optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    correct,total = 0,0\n",
    "    with torch.no_grad():\n",
    "        for x,y in tqdm(val_loader, desc=f\"Epoch {epoch}/20 [Val]\"):\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            preds = model(x).argmax(1)\n",
    "            correct += (preds==y).sum().item()\n",
    "            total   += y.size(0)\n",
    "    acc = 100*correct/total\n",
    "    print(f\"Epoch {epoch}: Train loss {total_loss/len(train_loader):.4f}, Val acc {acc:.2f}%\")\n",
    "    if acc > best_acc:\n",
    "        best_acc, counter = acc, 0\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "print(f\"Training complete! Best val acc: {best_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f9c917",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 8. Final evaluation on test set with metrics\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_loader, desc=\"Testing\"):\n",
    "        x = x.to(device)\n",
    "        preds = model(x).argmax(1).cpu().numpy()\n",
    "        y_pred.extend(preds)\n",
    "        y_true.extend(y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198804ed",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to numpy\n",
    "y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "\n",
    "# Metrics\n",
    "macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "weighted_f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "report = classification_report(y_true, y_pred, target_names=full_ds.classes)\n",
    "\n",
    "print(f\"\\nTest Accuracy: {(y_true == y_pred).mean()*100:.2f}%\")\n",
    "print(f\"Macro F1-score: {macro_f1:.4f}\")\n",
    "print(f\"Weighted F1-score: {weighted_f1:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"YlGnBu\", xticklabels=full_ds.classes, yticklabels=full_ds.classes)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
